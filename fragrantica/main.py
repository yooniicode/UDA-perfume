import time
import traceback
import undetected_chromedriver as uc
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import (
    NoSuchElementException,
    TimeoutException,
    ElementClickInterceptedException,
    WebDriverException,
)
import csv
import os
import sys
from tenacity import retry, stop_after_attempt, wait_exponential
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from queue import Queue
import random  # ëœë¤ ë”œë ˆì´ ë° UA ì„ íƒìš©

# -----------------------
# 1. ê¸°ë³¸ ì„¤ì • / ë¡œê·¸
# -----------------------

if sys.platform == 'win32':
    try:
        sys.stdout.reconfigure(encoding='utf-8')
        sys.stderr.reconfigure(encoding='utf-8')
    except (AttributeError, OSError):
        pass

logging.getLogger('selenium').setLevel(logging.WARNING)
logging.getLogger('urllib3').setLevel(logging.WARNING)
logging.getLogger('undetected_chromedriver').setLevel(logging.WARNING)
os.environ['WDM_LOG'] = '0'

# -----------------------
# 2. í¬ë¡¤ëŸ¬ ì„¤ì •
# -----------------------

# --- 2.1. ê¸°ë³¸ ì„¤ì • ---
SEARCH_KEYWORD = "chloe"
PERFUME_CSV_FILE = f'fragrantica_perfumes_{SEARCH_KEYWORD.lower().replace(" ", "-")}.csv'
REVIEW_CSV_FILE = f'fragrantica_reviews_{SEARCH_KEYWORD.lower().replace(" ", "-")}.csv'

# [ìˆ˜ì •] ê³ ì • ë”œë ˆì´ ëŒ€ì‹  ëœë¤ ë”œë ˆì´ ë²”ìœ„ ì‚¬ìš© (3ì´ˆ ~ 7ì´ˆ ì‚¬ì´)
RATE_LIMIT_DELAY_RANGE = (3.0, 7.0)
MAX_WORKERS = 3

# [ì¶”ê°€] User-Agent ë¦¬ìŠ¤íŠ¸ (ë¸Œë¼ìš°ì € ìœ„ì¥)
USER_AGENT_LIST = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2.1 Safari/605.1.15',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0'
]

# --- 2.2. CSV íŒŒì¼ í—¤ë” ---
PERFUME_FIELDNAMES = [
    'url', 'product_name', 'brand_name', 'target_gender', 'image_url',
    'top_notes', 'middle_notes', 'base_notes',
]
REVIEW_FIELDNAMES = [
    'product_name', 'review_content', 'review_date', 'reviewer_name'
]

# --- 2.3. ì„ íƒì (Selectors) ---
PRIMARY_PRODUCT_LINK_SELECTOR = (By.CSS_SELECTOR, "a.prefumeHbox")
FALLBACK_PRODUCT_LINK_SELECTOR = (By.CSS_SELECTOR, "a.perfumeHbox")
ALTERNATIVE_PRODUCT_LINK_SELECTOR = (By.CSS_SELECTOR, "div.perfume-card > a")

# [ì œí’ˆ ì •ë³´]
PRODUCT_NAME_H1_SELECTOR = (By.CSS_SELECTOR, 'h1[itemprop="name"]')
BRAND_NAME_SELECTOR = (By.CSS_SELECTOR, 'span[itemprop="brand"] a span')
TARGET_GENDER_SELECTOR = (By.CSS_SELECTOR, 'h1[itemprop="name"] small')
IMAGE_URL_SELECTOR = (By.CSS_SELECTOR, 'img[itemprop="image"]')

# [ë¦¬ë·° ì •ë³´]
REVIEW_HOLDER_SELECTOR = (By.ID, "all-reviews")
REVIEW_BODY_SELECTOR = (By.CSS_SELECTOR, "div[itemprop='reviewBody']")
REVIEW_CONTAINER_SELECTOR = (By.CSS_SELECTOR, 'div.fragrance-review-box[itemprop="review"]')
REVIEW_CONTENT_SELECTOR = (By.CSS_SELECTOR, 'div[itemprop="reviewBody"] p')
REVIEW_DATE_SELECTOR = (By.CSS_SELECTOR, 'span[itemprop="datePublished"]')
REVIEWER_NAME_SELECTOR = (By.CSS_SELECTOR, 'p > b > a[href*="member"]')

# --- 2.4. ìŠ¤ë ˆë“œ ë½ (Locks) ---
csv_lock = threading.Lock()
print_lock = threading.Lock()


# -----------------------
# 3. ë“œë¼ì´ë²„ í’€ í´ë˜ìŠ¤
# -----------------------

class DriverPool:
    """ë“œë¼ì´ë²„ë¥¼ ë¯¸ë¦¬ ìƒì„±í•˜ê³  ì¬ì‚¬ìš©í•˜ëŠ” í’€"""

    def __init__(self, size=3):
        self.pool = Queue(maxsize=size)
        self.size = size
        safe_print(f"\nğŸ”§ ë“œë¼ì´ë²„ í’€ ì´ˆê¸°í™” ì¤‘ ({size}ê°œ)...")
        for i in range(size):
            try:
                # [ìˆ˜ì •] ê° ë“œë¼ì´ë²„ì— ëœë¤ User-Agent í• ë‹¹
                user_agent = random.choice(USER_AGENT_LIST)
                driver = self._create_driver(user_agent=user_agent)
                self.pool.put(driver)
                safe_print(f"   âœ… ë“œë¼ì´ë²„ {i + 1}/{size} ìƒì„± ì™„ë£Œ (UA: {user_agent[:40]}...)")
                time.sleep(1)
            except Exception as e:
                safe_print(f"   âŒ ë“œë¼ì´ë²„ {i + 1} ìƒì„± ì‹¤íŒ¨: {repr(e)}")
        safe_print(f"âœ… ë“œë¼ì´ë²„ í’€ ì¤€ë¹„ ì™„ë£Œ\n")

    def _create_driver(self, user_agent=None):  # [ìˆ˜ì •] user_agent ì¸ìˆ˜ ì¶”ê°€
        """ë‹¨ì¼ ë“œë¼ì´ë²„ ìƒì„±"""
        options = uc.ChromeOptions()
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-gpu')
        options.add_argument('--disable-extensions')
        options.add_argument('--log-level=3')

        # [ìˆ˜ì •] ê¸°ë³¸ UA ëŒ€ì‹  ì„ íƒëœ ëœë¤ UA ì ìš©
        if user_agent:
            options.add_argument(f'--user-agent={user_agent}')
        else:
            # ê¸°ë³¸ UA (í´ë°±)
            options.add_argument(
                '--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
                'AppleWebKit/537.36 (KHTML, like Gecko) '
                'Chrome/120.0.0.0 Safari/537.36'
            )

        driver = uc.Chrome(options=options, use_subprocess=False)
        driver.implicitly_wait(3)
        return driver

    def get(self):
        return self.pool.get()

    def put(self, driver):
        self.pool.put(driver)

    def close_all(self):
        while not self.pool.empty():
            try:
                driver = self.pool.get_nowait()
                driver.quit()
            except:
                pass


# -----------------------
# 4. í—¬í¼ í•¨ìˆ˜
# -----------------------

def setup_csv_files():
    """CSV íŒŒì¼ì´ ì—†ìœ¼ë©´ í—¤ë”ì™€ í•¨ê»˜ ìƒì„±."""
    try:
        if not os.path.exists(PERFUME_CSV_FILE):
            with open(PERFUME_CSV_FILE, 'w', newline='', encoding='utf-8-sig') as f:
                writer = csv.DictWriter(f, fieldnames=PERFUME_FIELDNAMES)
                writer.writeheader()
        if not os.path.exists(REVIEW_CSV_FILE):
            with open(REVIEW_CSV_FILE, 'w', newline='', encoding='utf-8-sig') as f:
                writer = csv.DictWriter(f, fieldnames=REVIEW_FIELDNAMES)
                writer.writeheader()
    except PermissionError as e:
        print("\n" + "!" * 60)
        print(f"âŒ [ì¹˜ëª…ì  ì˜¤ë¥˜] íŒŒì¼ ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤: {e}")
        print(f"   '{PERFUME_CSV_FILE}' ë˜ëŠ” '{REVIEW_CSV_FILE}' íŒŒì¼ì´")
        print("   Excel ë“± ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ì—ì„œ ì—´ë ¤ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ëª¨ë‘ ë‹«ì€ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
        print("!" * 60 + "\n")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ CSV íŒŒì¼ ì„¤ì • ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)


def click_with_js(driver, element):
    try:
        driver.execute_script("arguments[0].click();", element)
    except Exception:
        pass


def safe_find_text(driver_or_element, *selector, wait_time=2, default=""):
    try:
        element = WebDriverWait(driver_or_element, wait_time).until(
            EC.presence_of_element_located(selector)
        )
        return element.text.strip()
    except (NoSuchElementException, TimeoutException):
        return default


def safe_find_attr(driver_or_element, *selector, attr="src", wait_time=2, default=""):
    try:
        element = WebDriverWait(driver_or_element, wait_time).until(
            EC.presence_of_element_located(selector)
        )
        return element.get_attribute(attr)
    except (NoSuchElementException, TimeoutException):
        return default


def get_notes_by_type(driver, note_type):
    """ 'Top Notes', 'Middle Notes', 'Base Notes' í—¤ë”ë¡œ ë…¸íŠ¸ë¥¼ ì°¾ìŠµë‹ˆë‹¤. """
    notes = []
    try:
        xpath = f"//h4[b='{note_type} Notes']/following-sibling::div[1]//div[contains(@style, 'margin')]/div[last()]"
        note_elements = driver.find_elements(By.XPATH, xpath)
        notes = [elem.text.strip() for elem in note_elements if elem.text.strip()]
    except Exception:
        pass
    return ", ".join(notes) if notes else ""


# ======================================================================

def get_undivided_notes(driver):
    """ 'Fragrance Notes' (í†µí•©) í—¤ë”ë¡œ ë…¸íŠ¸ë¥¼ ì°¾ìŠµë‹ˆë‹¤. """
    notes = []
    try:
        xpath = (
            "//span[contains(., 'Fragrance Notes')]/following::div"
            "[contains(@style, 'flex-flow: wrap') or contains(@style, 'flex-wrap: wrap')][1]"
            "/.//div[contains(@style, 'margin')]/div[last()]"
        )

        note_elements = driver.find_elements(By.XPATH, xpath)

        if not note_elements:
            xpath_h4 = (
                "//h4[b='Fragrance Notes']/following-sibling::div[1]"
                "/.//div[contains(@style, 'margin')]/div[last()]"
            )
            note_elements = driver.find_elements(By.XPATH, xpath_h4)

        notes = [elem.text.strip() for elem in note_elements if elem.text.strip()]
    except Exception:
        pass

    return ", ".join(notes) if notes else ""


class RateLimitError(Exception):
    """429 Too Many Requests ì˜ì‹¬ ì‹œ ì‚¬ìš©"""
    pass


def is_rate_limited_page(driver):
    """
    Cloudflare 429/ì°¨ë‹¨ í˜ì´ì§€ ì¶”ì •:
    - 'Too Many Requests' ê°™ì€ ë¬¸êµ¬
    - Cloudflare ì—ëŸ¬ í˜ì´ì§€ êµ¬ì¡° ë“±
    """
    try:
        html = driver.page_source.lower()
    except Exception:
        return False

    keywords = [
        "too many requests",
        "rate limited",
        "attention required",   # cloudflare challenge í˜ì´ì§€ ì œëª©
        "error 429",
    ]
    return any(k in html for k in keywords)


# ======================================================================

def write_batch_to_csv(filename, fieldnames, data_batch):
    if not data_batch:
        return
    with csv_lock:
        with open(filename, 'a', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writerows(data_batch)


def safe_print(message):
    with print_lock:
        print(message)


# -----------------------
# 5. URL ìˆ˜ì§‘ í•¨ìˆ˜
# -----------------------

def collect_all_product_urls(start_url, max_same_rounds=8, wait_between_scrolls=4.0):
    """Designers í˜ì´ì§€ì—ì„œ ëª¨ë“  ì œí’ˆ URL ìˆ˜ì§‘"""
    safe_print(f"ğŸš€ [1ë‹¨ê³„] '{start_url}'ì—ì„œ URL ìˆ˜ì§‘ ì‹œì‘...")
    options = uc.ChromeOptions()
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--start-maximized')
    options.add_argument(f'--user-agent={random.choice(USER_AGENT_LIST)}')

    driver = uc.Chrome(options=options, use_subprocess=False)
    wait = WebDriverWait(driver, 20)

    all_product_urls_set = set()

    selectors_to_try = [
        PRIMARY_PRODUCT_LINK_SELECTOR,
        FALLBACK_PRODUCT_LINK_SELECTOR,
        ALTERNATIVE_PRODUCT_LINK_SELECTOR
    ]
    selector_in_use = None

    try:
        driver.get(start_url)
        time.sleep(3)  # ì´ˆê¸° ë¡œë”© ëŒ€ê¸°
        safe_print(f"âœ… '{start_url}' ì ‘ì† ì™„ë£Œ")

        # ğŸ”§ ì„ íƒì ì°¾ê¸°
        for i, selector in enumerate(selectors_to_try):
            try:
                wait.until(EC.presence_of_element_located(selector))
                selector_in_use = selector
                safe_print(f"ğŸ” ì„ íƒì #{i + 1} ë¡œ ì œí’ˆ ìš”ì†Œ í™•ì¸ë¨.")
                break
            except TimeoutException:
                safe_print(f"âš ï¸ ì„ íƒì #{i + 1} ì—†ìŒ. ë‹¤ìŒ ì‹œë„...")

        if not selector_in_use:
            safe_print("âŒ ëª¨ë“  ì„ íƒìë¡œ ìš”ì†Œë¥¼ ì°¾ì§€ ëª»í•¨. selectorë¥¼ ë‹¤ì‹œ í™•ì¸í•˜ì„¸ìš”.")
            return []

        # ğŸ”§ í˜ì´ì§€ë„¤ì´ì…˜ í™•ì¸
        pagination_links = driver.find_elements(By.CSS_SELECTOR, 'div.pagination a')

        if not pagination_links:
            # --- ë¬´í•œ ìŠ¤í¬ë¡¤ ë°©ì‹ ---
            safe_print("   (i) 'ë¬´í•œ ìŠ¤í¬ë¡¤' ë°©ì‹ìœ¼ë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤")
            prev_count = 0
            same_rounds = 0
            last_height = driver.execute_script("return document.body.scrollHeight")
            scroll_attempt = 0

            while True:
                scroll_attempt += 1
                safe_print(f"   ğŸ”„ ìŠ¤í¬ë¡¤ ì‹œë„ #{scroll_attempt}")

                try:
                    elements = driver.find_elements(*selector_in_use)
                    if not elements and prev_count == 0:
                        try:
                            wait.until(EC.presence_of_element_located(selector_in_use))
                            elements = driver.find_elements(*selector_in_use)
                        except TimeoutException:
                            safe_print("... ì•„ì§ ì œí’ˆ ìš”ì†Œê°€ ì—†ìŒ (ì ì‹œ í›„ ì¬ì‹œë„)")

                    page_urls = [e.get_attribute('href') for e in elements if e.get_attribute('href')]
                    newly_found = set(page_urls) - all_product_urls_set
                    if newly_found:
                        all_product_urls_set.update(newly_found)
                        safe_print(f"â• ìƒˆ URL {len(newly_found)}ê°œ ë°œê²¬ (ëˆ„ì : {len(all_product_urls_set)})")
                        same_rounds = 0

                    # ìŠ¤í¬ë¡¤ ë°©ì‹ ê°œì„ 
                    if elements:
                        driver.execute_script(
                            "arguments[0].scrollIntoView({behavior:'smooth', block:'end'});",
                            elements[-1]
                        )
                        time.sleep(1)
                        driver.execute_script("window.scrollBy(0, 500);")
                    else:
                        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")

                    time.sleep(wait_between_scrolls)

                    # ìš”ì†Œ ì¦ê°€ ëŒ€ê¸°
                    try:
                        WebDriverWait(driver, 10).until(
                            lambda d: len(d.find_elements(*selector_in_use)) > prev_count
                        )
                        prev_count = len(driver.find_elements(*selector_in_use))
                        same_rounds = 0
                        safe_print("ğŸ”„ ìš”ì†Œ ìˆ˜ ì¦ê°€ í™•ì¸ â€” ê³„ì† ìˆ˜ì§‘")
                    except TimeoutException:
                        same_rounds += 1
                        safe_print(f"â± ë³€í™” ì—†ìŒ (ì—°ì† {same_rounds}/{max_same_rounds})")

                    new_height = driver.execute_script("return document.body.scrollHeight")
                    if new_height == last_height:
                        same_rounds += 1
                        safe_print(f"ğŸ“ í˜ì´ì§€ ë†’ì´ ë³€í™” ì—†ìŒ (ì—°ì†: {same_rounds})")
                    else:
                        last_height = new_height
                        same_rounds = 0

                    if same_rounds >= max_same_rounds:
                        safe_print("ğŸ ë” ì´ìƒì˜ ì½˜í…ì¸  ë¡œë“œ ì—†ìŒ. ìˆ˜ì§‘ ì¢…ë£Œ.")
                        break

                    if scroll_attempt > 100:
                        safe_print("âš ï¸ ìµœëŒ€ ìŠ¤í¬ë¡¤ ì‹œë„ íšŸìˆ˜ ë„ë‹¬. ì¢…ë£Œ.")
                        break

                except Exception as e:
                    safe_print(f"âš ï¸ ë¬´í•œ ìŠ¤í¬ë¡¤ ì¤‘ ì˜ˆì™¸: {repr(e)}")
                    break
        else:
            # --- í˜ì´ì§€ë„¤ì´ì…˜ ë°©ì‹ ---
            safe_print("   (i) 'í˜ì´ì§€ë„¤ì´ì…˜' ë°©ì‹ìœ¼ë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤")
            page_num = 1
            while True:
                try:
                    wait.until(EC.presence_of_element_located(selector_in_use))
                    elements = driver.find_elements(*selector_in_use)

                    page_urls = []
                    for elem in elements:
                        href = elem.get_attribute('href')
                        if href and href.startswith("https://www.fragrantica.com/perfume/"):
                            page_urls.append(href)

                    new_urls_count = len(set(page_urls) - all_product_urls_set)
                    all_product_urls_set.update(page_urls)
                    safe_print(f"ğŸ“„ í˜ì´ì§€ {page_num}: {new_urls_count}ê°œ ì‹ ê·œ ìˆ˜ì§‘ (ëˆ„ì : {len(all_product_urls_set)}ê°œ)")

                except TimeoutException:
                    safe_print(f"âš ï¸  í˜ì´ì§€ {page_num}ì—ì„œ ì œí’ˆ ë§í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")

                try:
                    next_button = wait.until(
                        EC.element_to_be_clickable((By.CSS_SELECTOR, 'a[aria-label="Next Â»"]'))
                    )
                    click_with_js(driver, next_button)
                    time.sleep(3)
                    page_num += 1
                except (TimeoutException, NoSuchElementException):
                    safe_print("ğŸ ë” ì´ìƒ 'ë‹¤ìŒ' í˜ì´ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. URL ìˆ˜ì§‘ ì¢…ë£Œ.")
                    break

    except Exception as e:
        safe_print(f"âŒ URL ìˆ˜ì§‘ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {repr(e)}")
        traceback.print_exc()
    finally:
        safe_print("====== ğŸ”§ URL ìˆ˜ì§‘ ë“œë¼ì´ë²„ ì¢…ë£Œ ======")
        driver.quit()

    return list(all_product_urls_set)

# -----------------------
# 6. í•µì‹¬ ìŠ¤í¬ë˜í•‘ í•¨ìˆ˜
# -----------------------

@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
def scrape_product_details(driver, url):
    """
    ì œí’ˆ ìƒì„¸ í˜ì´ì§€ì—ì„œ í–¥ìˆ˜ ì •ë³´ë¥¼ ìŠ¤í¬ë©.
    """
    wait = WebDriverWait(driver, 10)

    h1_element = wait.until(
        EC.presence_of_element_located(PRODUCT_NAME_H1_SELECTOR)
    )

    product_name = driver.execute_script(
        "return arguments[0].firstChild.textContent.trim()", h1_element
    )
    brand_name = safe_find_text(h1_element, *BRAND_NAME_SELECTOR, default=SEARCH_KEYWORD.title())
    target_gender = safe_find_text(h1_element, *TARGET_GENDER_SELECTOR, default="NA")

    image_url = safe_find_attr(driver, *IMAGE_URL_SELECTOR, attr="src", default="")

    # --- ë…¸íŠ¸ ìˆ˜ì§‘ ---
    top_notes = get_notes_by_type(driver, "Top")
    middle_notes = get_notes_by_type(driver, "Middle")
    base_notes = get_notes_by_type(driver, "Base")

    if not top_notes and not middle_notes and not base_notes:
        safe_print(f"      ... {product_name}: T/M/B ë…¸íŠ¸ ì—†ìŒ. 'Fragrance Notes' í†µí•© ê²€ìƒ‰ ì‹œë„...")
        undivided_notes = get_undivided_notes(driver)
        if undivided_notes:
            middle_notes = undivided_notes
            safe_print(f"      ... {product_name}: í†µí•© ë…¸íŠ¸ ë°œê²¬. Middleì— ì €ì¥.")

    product_data = {
        'url': url,
        'product_name': product_name,
        'brand_name': brand_name,
        'target_gender': target_gender,
        'image_url': image_url,
        'top_notes': top_notes,
        'middle_notes': middle_notes,
        'base_notes': base_notes,
    }

    return product_name, product_data


def scrape_reviews(driver, product_name, base_url):
    """
    [15ì°¨ ìµœì¢…] #all-reviews ì•µì»¤ ë§í¬ë¡œ ì§ì ‘ ì´ë™
    """
    reviews_batch = []
    processed_review_identifiers = set()

    try:
        # ğŸ”§ STEP 1: ë¦¬ë·° ì„¹ì…˜ìœ¼ë¡œ ì§ì ‘ ì´ë™
        review_url = base_url + "#all-reviews"
        safe_print(f"      ... {product_name}: ë¦¬ë·° ì„¹ì…˜ìœ¼ë¡œ ì´ë™ ({review_url})")

        # 429 / ì°¨ë‹¨ í˜ì´ì§€ ê°ì§€ìš© ì¬ì‹œë„ ë£¨í”„
        max_attempts = 30
        for attempt in range(1, max_attempts + 1):
            driver.get(review_url)
            time.sleep(4)  # ê¸°ë³¸ ë¡œë”© ëŒ€ê¸°

            if not is_rate_limited_page(driver):
                # ì •ìƒ í˜ì´ì§€ë©´ ë°”ë¡œ ì§„í–‰
                break

            # ì—¬ê¸°ê¹Œì§€ ì™”ë‹¤ = rate limit ì˜ì‹¬
            wait_sec = random.randint(60, 180)  # 1~3ë¶„ ëœë¤ ëŒ€ê¸°
            safe_print(
                f"      â± {product_name}: ë¦¬ë·° ìš”ì²­ì´ rate limitì— ê±¸ë¦° ê²ƒ ê°™ì•„ìš” "
                f"({attempt}/{max_attempts}) â†’ {wait_sec}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„"
            )
            time.sleep(wait_sec)
        else:
            # for-else: 3ë²ˆ ëª¨ë‘ rate-limitedì˜€ë‹¤ë©´ ë¦¬ë·°ëŠ” í¬ê¸°í•˜ê³  ë„˜ì–´ê°
            safe_print(f"      âŒ {product_name}: 3ë²ˆ ì‹œë„í–ˆì§€ë§Œ ë¦¬ë·° í˜ì´ì§€ê°€ ì—´ë¦¬ì§€ ì•Šì•„, ë¦¬ë·°ëŠ” ê±´ë„ˆëœë‹ˆë‹¤.")
            return []

        # ğŸ”§ STEP 2: ë¦¬ë·° ì„¹ì…˜ ì¡´ì¬ í™•ì¸
        section_exists = driver.execute_script("""
            var section = document.getElementById('all-reviews');
            return section !== null;
        """)

        if not section_exists:
            safe_print(f"      â„¹ï¸  {product_name}: ë¦¬ë·° ì„¹ì…˜ ì—†ìŒ -> ë¦¬ë·° 0ê°œ")
            return []

        safe_print(f"      âœ… {product_name}: ë¦¬ë·° ì„¹ì…˜ ë°œê²¬!")
        time.sleep(2)

        # ğŸ”§ STEP 3: ë¦¬ë·° ì»¨í…Œì´ë„ˆ í™•ì¸
        review_count = driver.execute_script("""
            return document.querySelectorAll('div.fragrance-review-box[itemprop="review"]').length;
        """)

        safe_print(f"      ... {product_name}: {review_count}ê°œ ë¦¬ë·° ì»¨í…Œì´ë„ˆ ê°ì§€ë¨")

        if review_count == 0:
            safe_print(f"      â„¹ï¸  {product_name}: ë¦¬ë·° ì—†ìŒ -> ë¦¬ë·° 0ê°œ")
            return []

        # ğŸ”§ STEP 4: ë¬´í•œ ìŠ¤í¬ë¡¤ë¡œ ëª¨ë“  ë¦¬ë·° ë¡œë“œ
        safe_print(f"      ... {product_name}: ëª¨ë“  ë¦¬ë·° ë¡œë”© ì¤‘...")
        previous_count = 0
        no_change_count = 0
        max_no_change = 5

        while no_change_count < max_no_change:
            current_count = driver.execute_script("""
                var reviews = document.querySelectorAll('div.fragrance-review-box[itemprop="review"]');
                if (reviews.length > 0) {
                    reviews[reviews.length - 1].scrollIntoView({block: 'end', behavior: 'smooth'});
                }
                return reviews.length;
            """)

            if current_count > previous_count:
                safe_print(f"      ğŸ“ {product_name}: {current_count}ê°œ ë¦¬ë·° ë¡œë“œë¨...")
                previous_count = current_count
                no_change_count = 0
                time.sleep(3)
            else:
                no_change_count += 1
                safe_print(f"      â± {product_name}: ë³€í™” ì—†ìŒ ({no_change_count}/{max_no_change})")
                time.sleep(2)

        safe_print(f"      âœ… {product_name}: ì´ {previous_count}ê°œ ë¦¬ë·° ë¡œë“œ ì™„ë£Œ")
        time.sleep(2)

        # ğŸ”§ STEP 5: ëª¨ë“  ë¦¬ë·° ì¶”ì¶œ
        review_elements = driver.find_elements(By.CSS_SELECTOR, 'div.fragrance-review-box[itemprop="review"]')
        safe_print(f"      ... {product_name}: {len(review_elements)}ê°œ ë¦¬ë·° ì¶”ì¶œ ì‹œì‘...")

        for idx, review in enumerate(review_elements, 1):
            try:
                # ë¦¬ë·°ì–´ ì´ë¦„
                reviewer_name_text = "Guest"
                try:
                    meta_name = review.find_element(By.CSS_SELECTOR, 'meta[itemprop="name"]')
                    reviewer_name_text = meta_name.get_attribute("content")
                except:
                    pass

                # ë‚ ì§œ
                review_date_text = "NA"
                try:
                    date_span = review.find_element(By.CSS_SELECTOR, 'span[itemprop="datePublished"]')
                    review_date_text = date_span.text.strip()
                except:
                    pass

                # ë¦¬ë·° ë‚´ìš©
                content = ""
                try:
                    content_div = review.find_element(By.CSS_SELECTOR, 'div[itemprop="reviewBody"]')
                    paragraphs = content_div.find_elements(By.TAG_NAME, 'p')
                    content = " ".join([p.text.strip() for p in paragraphs if p.text.strip()])
                except:
                    pass

                # ì¤‘ë³µ ì²´í¬
                unique_id = (reviewer_name_text, review_date_text, content[:50])

                if unique_id in processed_review_identifiers:
                    continue

                processed_review_identifiers.add(unique_id)

                if content:
                    reviews_batch.append({
                        'product_name': product_name,
                        'review_content': content,
                        'review_date': review_date_text,
                        'reviewer_name': reviewer_name_text,
                    })

                    if idx % 20 == 0:
                        safe_print(f"      ... {product_name}: {len(reviews_batch)}ê°œ ì²˜ë¦¬ ì¤‘...")

            except Exception as e:
                continue

        safe_print(f"      âœ… {product_name}: ì´ {len(reviews_batch)}ê°œ ë¦¬ë·° ìˆ˜ì§‘ ì™„ë£Œ")
        return reviews_batch

    except Exception as e:
        safe_print(f"      âŒ {product_name}: ë¦¬ë·° ìˆ˜ì§‘ ì—ëŸ¬: {repr(e)}")
        traceback.print_exc()
        return []

# -----------------------
# 7. ì›Œì»¤ í•¨ìˆ˜
# -----------------------

def process_single_product(args, driver_pool):
    """ë‹¨ì¼ ì œí’ˆ ì²˜ë¦¬ (ë“œë¼ì´ë²„ í’€ ì‚¬ìš©)."""
    url, index, total = args
    driver = None
    product_name = url.split('/')[-1]

    try:
        driver = driver_pool.get()

        # 1ï¸âƒ£ ì œí’ˆ í˜ì´ì§€ ì ‘ì† ë° ì •ë³´ ìˆ˜ì§‘
        driver.get(url)
        product_name, product_data = scrape_product_details(driver, url)
        write_batch_to_csv(PERFUME_CSV_FILE, PERFUME_FIELDNAMES, [product_data])

        # 2ï¸âƒ£ í˜ì´ì§€ ì „ì²´ ìŠ¤í¬ë¡¤ (Lazy Loading íŠ¸ë¦¬ê±°)
        safe_print(f"      ... {product_name}: í˜ì´ì§€ ì „ì²´ ìŠ¤í¬ë¡¤ ì¤‘...")
        last_height = driver.execute_script("return document.body.scrollHeight")
        scroll_position = 0
        scroll_step = 800

        while scroll_position < last_height:
            scroll_position += scroll_step
            driver.execute_script(f"window.scrollTo(0, {scroll_position});")
            time.sleep(1)

            new_height = driver.execute_script("return document.body.scrollHeight")
            if new_height > last_height:
                last_height = new_height

        safe_print(f"      âœ… {product_name}: í˜ì´ì§€ ì „ì²´ ìŠ¤í¬ë¡¤ ì™„ë£Œ")
        time.sleep(2)

        # 3ï¸âƒ£ ë¦¬ë·° ìˆ˜ì§‘ (#all-reviewsë¡œ ì¬ì ‘ì†)
        reviews_batch = scrape_reviews(driver, product_name, url)
        if reviews_batch:
            write_batch_to_csv(REVIEW_CSV_FILE, REVIEW_FIELDNAMES, reviews_batch)

        # ë”œë ˆì´
        delay = random.uniform(*RATE_LIMIT_DELAY_RANGE)
        safe_print(f"      ... ë‹¤ìŒ ì‘ì—…ê¹Œì§€ {delay:.1f}ì´ˆ ëŒ€ê¸° ...")
        time.sleep(delay)

        driver_pool.put(driver)

        return {
            'status': 'success',
            'product_name': product_name,
            'review_count': len(reviews_batch),
            'index': index,
            'total': total
        }

    except Exception as e:
        if driver:
            safe_print(f"  (i) {product_name} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ. ë“œë¼ì´ë²„ ì¬ì‹œì‘...")
            try:
                driver.quit()
            except:
                pass

            try:
                new_user_agent = random.choice(USER_AGENT_LIST)
                new_driver = driver_pool._create_driver(user_agent=new_user_agent)
                driver_pool.put(new_driver)
                safe_print(f"  (i) ìƒˆ ë“œë¼ì´ë²„ ìƒì„± í›„ í’€ì— ë°˜í™˜ ì™„ë£Œ.")
            except Exception as e_create:
                safe_print(f"  (E) ìƒˆ ë“œë¼ì´ë²„ ìƒì„± ì‹¤íŒ¨: {e_create}.")
                pass

        return {
            'status': 'failed',
            'error': repr(e)[:120],
            'url': url,
            'index': index,
            'total': total
        }

# -----------------------
# 8. ë©”ì¸ ì‹¤í–‰
# -----------------------

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (ë“œë¼ì´ë²„ í’€ ì‚¬ìš©)."""
    start_time = time.time()

    print("=" * 60)
    print(f"ğŸš€ Fragrantica í¬ë¡¤ëŸ¬ ì‹œì‘ (í‚¤ì›Œë“œ: {SEARCH_KEYWORD})")
    print(f"   (ë“œë¼ì´ë²„ í’€: {MAX_WORKERS}ê°œ)")
    print("=" * 60)

    setup_csv_files()

    formatted_keyword = SEARCH_KEYWORD.title()
    formatted_keyword = formatted_keyword.replace(" ", "-")
    start_url = f"https://www.fragrantica.com/designers/{formatted_keyword}.html"

    url_collection_start = time.time()
    product_urls = collect_all_product_urls(start_url)
    url_collection_time = time.time() - url_collection_start

    if not product_urls:
        print(f"âŒ '{SEARCH_KEYWORD}'(ë³€í™˜: {formatted_keyword})ì— ëŒ€í•œ URLì´ ìˆ˜ì§‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    print(f"âœ… ì´ {len(product_urls)}ê°œ ì œí’ˆ ë°œê²¬ (ì†Œìš” ì‹œê°„: {url_collection_time:.1f}ì´ˆ)")

    avg_delay = sum(RATE_LIMIT_DELAY_RANGE) / 2
    avg_time_per_product = 8 + avg_delay
    estimated_time_parallel = (len(product_urls) * avg_time_per_product) / MAX_WORKERS
    print(f"\nğŸ“Š ì˜ˆìƒ ì†Œìš” ì‹œê°„ ({MAX_WORKERS}ê°œ ë³‘ë ¬, í‰ê·  ë”œë ˆì´ {avg_delay:.1f}ì´ˆ í¬í•¨): ì•½ {estimated_time_parallel / 60:.1f}ë¶„")

    driver_pool = DriverPool(size=MAX_WORKERS)

    print("\n[2ë‹¨ê³„] ì œí’ˆ ìŠ¤í¬ë˜í•‘ ì‹œì‘ (ë“œë¼ì´ë²„ í’€ ì‚¬ìš©)...")
    print("-" * 60)

    scraping_start = time.time()
    total = len(product_urls)
    tasks = [(url, i + 1, total) for i, url in enumerate(product_urls)]

    success_count = 0
    failed_count = 0

    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {
            executor.submit(process_single_product, task, driver_pool): task
            for task in tasks
        }

        for future in as_completed(futures):
            result = future.result()
            percentage = (result['index'] / result['total']) * 100

            if result['status'] == 'success':
                success_count += 1
                if result['review_count'] > 0:
                    safe_print(
                        f"[{result['index']}/{result['total']} ({percentage:.1f}%)] âœ… {result['product_name']} - ë¦¬ë·° {result['review_count']}ê°œ")
                else:
                    safe_print(
                        f"[{result['index']}/{result['total']} ({percentage:.1f}%)] âœ… {result['product_name']} - ì œí’ˆ ì •ë³´ë§Œ")
            else:
                failed_count += 1
                safe_print(
                    f"[{result['index']}/{result['total']} ({percentage:.1f}%)] âŒ ì²˜ë¦¬ ì‹¤íŒ¨ - {result['url']} - {result['error']}")

    print("\nğŸ”§ ë“œë¼ì´ë²„ í’€ ì¢…ë£Œ ì¤‘...")
    driver_pool.close_all()

    scraping_time = time.time() - scraping_start
    total_time = time.time() - start_time

    print("-" * 60)
    print("\n" + "=" * 60)
    print("âœ… ëª¨ë“  í¬ë¡¤ë§ ì™„ë£Œ!")
    print("=" * 60)
    print(f"\nğŸ“Š í†µê³„:")
    print(f"   - ì„±ê³µ: {success_count}ê°œ")
    print(f"   - ì‹¤íŒ¨: {failed_count}ê°œ")
    print(f"\nâ±ï¸  ì†Œìš” ì‹œê°„:")
    print(f"   - URL ìˆ˜ì§‘: {url_collection_time:.1f}ì´ˆ")
    print(f"   - ì œí’ˆ ìŠ¤í¬ë˜í•‘: {scraping_time / 60:.1f}ë¶„")
    print(f"   - ì „ì²´: {total_time / 60:.1f}ë¶„")
    print(f"\nğŸ“ ì €ì¥ëœ íŒŒì¼:")
    print(f"   - {PERFUME_CSV_FILE}")
    print(f"   - {REVIEW_CSV_FILE}")
    print("=" * 60)


if __name__ == "__main__":
    main()