import time
import traceback
import undetected_chromedriver as uc
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import (
    NoSuchElementException,
    TimeoutException,
    ElementClickInterceptedException,
    WebDriverException,
)
import csv
import os
import sys
from tenacity import retry, stop_after_attempt, wait_exponential
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from queue import Queue
import random

# -----------------------
# 1. ê¸°ë³¸ ì„¤ì • / ë¡œê·¸
# -----------------------

if sys.platform == 'win32':
    try:
        sys.stdout.reconfigure(encoding='utf-8')
        sys.stderr.reconfigure(encoding='utf-8')
    except (AttributeError, OSError):
        pass

logging.getLogger('selenium').setLevel(logging.WARNING)
logging.getLogger('urllib3').setLevel(logging.WARNING)
logging.getLogger('undetected_chromedriver').setLevel(logging.WARNING)
os.environ['WDM_LOG'] = '0'

# -----------------------
# 2. í¬ë¡¤ëŸ¬ ì„¤ì •
# -----------------------

# --- 2.1. ê¸°ë³¸ ì„¤ì • ---
SEARCH_KEYWORD = "burberry"
PERFUME_CSV_FILE = f'fragrantica_perfumes_{SEARCH_KEYWORD.lower().replace(" ", "-")}.csv'
REVIEW_CSV_FILE = f'fragrantica_reviews_{SEARCH_KEYWORD.lower().replace(" ", "-")}.csv'

RATE_LIMIT_DELAY_RANGE = (3.0, 7.0)
MAX_WORKERS = 3

USER_AGENT_LIST = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2.1 Safari/605.1.15',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0'
]

# --- 2.2. CSV íŒŒì¼ í—¤ë” ---
REVIEW_FIELDNAMES = [
    'product_name', 'review_content', 'review_date', 'reviewer_name'
]

# --- 2.3. ìŠ¤ë ˆë“œ ë½ ---
csv_lock = threading.Lock()
print_lock = threading.Lock()


# -----------------------
# 3. ë“œë¼ì´ë²„ í’€ í´ë˜ìŠ¤
# -----------------------

class DriverPool:
    """ë“œë¼ì´ë²„ë¥¼ ë¯¸ë¦¬ ìƒì„±í•˜ê³  ì¬ì‚¬ìš©í•˜ëŠ” í’€"""

    def __init__(self, size=3):
        self.pool = Queue(maxsize=size)
        self.size = size
        safe_print(f"\nğŸ”§ ë“œë¼ì´ë²„ í’€ ì´ˆê¸°í™” ì¤‘ ({size}ê°œ)...")
        for i in range(size):
            try:
                user_agent = random.choice(USER_AGENT_LIST)
                driver = self._create_driver(user_agent=user_agent)
                self.pool.put(driver)
                safe_print(f"   âœ… ë“œë¼ì´ë²„ {i + 1}/{size} ìƒì„± ì™„ë£Œ")
                time.sleep(1)
            except Exception as e:
                safe_print(f"   âŒ ë“œë¼ì´ë²„ {i + 1} ìƒì„± ì‹¤íŒ¨: {repr(e)}")
        safe_print(f"âœ… ë“œë¼ì´ë²„ í’€ ì¤€ë¹„ ì™„ë£Œ\n")

    def _create_driver(self, user_agent=None):
        """ë‹¨ì¼ ë“œë¼ì´ë²„ ìƒì„±"""
        options = uc.ChromeOptions()
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-gpu')
        options.add_argument('--disable-extensions')
        options.add_argument('--log-level=3')

        if user_agent:
            options.add_argument(f'--user-agent={user_agent}')
        else:
            options.add_argument(
                '--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
                'AppleWebKit/537.36 (KHTML, like Gecko) '
                'Chrome/120.0.0.0 Safari/537.36'
            )

        driver = uc.Chrome(options=options, use_subprocess=False)
        driver.implicitly_wait(3)
        return driver

    def get(self):
        return self.pool.get()

    def put(self, driver):
        self.pool.put(driver)

    def close_all(self):
        while not self.pool.empty():
            try:
                driver = self.pool.get_nowait()
                driver.quit()
            except:
                pass


# -----------------------
# 4. í—¬í¼ í•¨ìˆ˜
# -----------------------

def write_batch_to_csv(filename, fieldnames, data_batch):
    if not data_batch:
        return
    with csv_lock:
        with open(filename, 'a', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writerows(data_batch)


def safe_print(message):
    with print_lock:
        print(message)


def is_rate_limited_page(driver):
    """Cloudflare 429/ì°¨ë‹¨ í˜ì´ì§€ ì¶”ì •"""
    try:
        html = driver.page_source.lower()
    except Exception:
        return False

    keywords = [
        "too many requests",
        "rate limited",
        "attention required",
        "error 429",
    ]
    return any(k in html for k in keywords)


# -----------------------
# 5. ë¦¬ë·° ìˆ˜ì§‘ í•¨ìˆ˜
# -----------------------

def scrape_reviews(driver, product_name, base_url):
    """
    ë¦¬ë·° ìˆ˜ì§‘ (ë‹¤ì¤‘ ì „ëµ)
    """
    reviews_batch = []
    processed_review_identifiers = set()

    try:
        # ğŸ”§ STEP 1: ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ ë¦¬ë·° ì„¹ì…˜ ì°¾ê¸°
        safe_print(f"      ... {product_name}: ë¦¬ë·° ì„¹ì…˜ íƒìƒ‰ ì¤‘...")

        # Rate limit ì²´í¬ ë° ì¬ì‹œë„
        max_attempts = 3
        for attempt in range(1, max_attempts + 1):
            review_url = base_url + "#all-reviews"
            driver.get(review_url)
            time.sleep(4)

            if not is_rate_limited_page(driver):
                break

            wait_sec = random.randint(60, 180)
            safe_print(
                f"      â± {product_name}: Rate limit ê°ì§€ "
                f"({attempt}/{max_attempts}) â†’ {wait_sec}ì´ˆ ëŒ€ê¸°"
            )
            time.sleep(wait_sec)
        else:
            safe_print(f"      âŒ {product_name}: Rate limitìœ¼ë¡œ ë¦¬ë·° ìˆ˜ì§‘ ì‹¤íŒ¨")
            return []

        # ë°©ë²• 1: #all-reviews ì•µì»¤ë¡œ ì´ë™
        section_exists = driver.execute_script("""
            // ì—¬ëŸ¬ ê°€ëŠ¥í•œ ì„ íƒì ì‹œë„
            var section = document.getElementById('all-reviews') ||
                         document.querySelector('[id*="review"]') ||
                         document.querySelector('.reviews-container') ||
                         document.querySelector('div[class*="review"]');

            if (section) {
                section.scrollIntoView({behavior: 'smooth', block: 'center'});
                return true;
            }
            return false;
        """)

        if not section_exists:
            # ë°©ë²• 2: ë¦¬ë·° ì»¨í…Œì´ë„ˆë¥¼ ì§ì ‘ ì°¾ì•„ë³´ê¸°
            try:
                review_containers = driver.find_elements(By.CSS_SELECTOR,
                                                         'div.fragrance-review-box[itemprop="review"]')
                if review_containers:
                    safe_print(f"      âœ… {product_name}: ë¦¬ë·° ì»¨í…Œì´ë„ˆ ì§ì ‘ ë°œê²¬!")
                    section_exists = True
                    driver.execute_script(
                        "arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});",
                        review_containers[0]
                    )
                    time.sleep(2)
            except:
                pass

        if not section_exists:
            safe_print(f"      â„¹ï¸  {product_name}: ë¦¬ë·° ì„¹ì…˜ ì—†ìŒ -> ë¦¬ë·° 0ê°œ")
            return []

        safe_print(f"      âœ… {product_name}: ë¦¬ë·° ì„¹ì…˜ ë°œê²¬!")
        time.sleep(2)

        # ğŸ”§ STEP 2: ë¦¬ë·° ì»¨í…Œì´ë„ˆ í™•ì¸
        review_count = driver.execute_script("""
            var reviews = document.querySelectorAll('div.fragrance-review-box[itemprop="review"]');
            if (reviews.length === 0) {
                reviews = document.querySelectorAll('div[class*="review-box"]') ||
                         document.querySelectorAll('div[itemprop="review"]') ||
                         document.querySelectorAll('.review-container');
            }
            return reviews.length;
        """)

        safe_print(f"      ... {product_name}: {review_count}ê°œ ë¦¬ë·° ì»¨í…Œì´ë„ˆ ê°ì§€ë¨")

        if review_count == 0:
            safe_print(f"      â„¹ï¸  {product_name}: ë¦¬ë·° ì—†ìŒ -> ë¦¬ë·° 0ê°œ")
            return []

        # ğŸ”§ STEP 3: ë¬´í•œ ìŠ¤í¬ë¡¤ë¡œ ëª¨ë“  ë¦¬ë·° ë¡œë“œ
        safe_print(f"      ... {product_name}: ëª¨ë“  ë¦¬ë·° ë¡œë”© ì¤‘...")
        previous_count = 0
        no_change_count = 0
        max_no_change = 5

        while no_change_count < max_no_change:
            current_count = driver.execute_script("""
                var reviews = document.querySelectorAll('div.fragrance-review-box[itemprop="review"]');
                if (reviews.length > 0) {
                    reviews[reviews.length - 1].scrollIntoView({block: 'end', behavior: 'smooth'});
                }
                return reviews.length;
            """)

            if current_count > previous_count:
                safe_print(f"      ğŸ“ {product_name}: {current_count}ê°œ ë¦¬ë·° ë¡œë“œë¨...")
                previous_count = current_count
                no_change_count = 0
                time.sleep(3)
            else:
                no_change_count += 1
                safe_print(f"      â± {product_name}: ë³€í™” ì—†ìŒ ({no_change_count}/{max_no_change})")
                time.sleep(2)

        safe_print(f"      âœ… {product_name}: ì´ {previous_count}ê°œ ë¦¬ë·° ë¡œë“œ ì™„ë£Œ")
        time.sleep(2)

        # ğŸ”§ STEP 4: ëª¨ë“  ë¦¬ë·° ì¶”ì¶œ
        review_elements = driver.find_elements(By.CSS_SELECTOR, 'div.fragrance-review-box[itemprop="review"]')

        # ëŒ€ì²´ ì„ íƒì ì‹œë„
        if not review_elements:
            safe_print(f"      ... {product_name}: ê¸°ë³¸ ì„ íƒì ì‹¤íŒ¨, ëŒ€ì²´ ì„ íƒì ì‹œë„...")
            review_elements = driver.find_elements(By.CSS_SELECTOR, 'div[itemprop="review"]')

        if not review_elements:
            review_elements = driver.find_elements(By.CSS_SELECTOR, 'div[class*="review-box"]')

        safe_print(f"      ... {product_name}: {len(review_elements)}ê°œ ë¦¬ë·° ì¶”ì¶œ ì‹œì‘...")

        for idx, review in enumerate(review_elements, 1):
            try:
                # ë¦¬ë·°ì–´ ì´ë¦„
                reviewer_name_text = "Guest"
                try:
                    meta_name = review.find_element(By.CSS_SELECTOR, 'meta[itemprop="name"]')
                    reviewer_name_text = meta_name.get_attribute("content")
                except:
                    try:
                        reviewer_link = review.find_element(By.CSS_SELECTOR, 'a[href*="member"]')
                        reviewer_name_text = reviewer_link.text.strip()
                    except:
                        pass

                # ë‚ ì§œ
                review_date_text = "NA"
                try:
                    date_span = review.find_element(By.CSS_SELECTOR, 'span[itemprop="datePublished"]')
                    review_date_text = date_span.text.strip()
                except:
                    try:
                        date_meta = review.find_element(By.CSS_SELECTOR, 'meta[itemprop="datePublished"]')
                        review_date_text = date_meta.get_attribute("content")
                    except:
                        pass

                # ë¦¬ë·° ë‚´ìš©
                content = ""
                try:
                    content_div = review.find_element(By.CSS_SELECTOR, 'div[itemprop="reviewBody"]')
                    paragraphs = content_div.find_elements(By.TAG_NAME, 'p')
                    content = " ".join([p.text.strip() for p in paragraphs if p.text.strip()])
                except:
                    try:
                        content_div = review.find_element(By.CSS_SELECTOR, 'div[itemprop="reviewBody"]')
                        content = content_div.text.strip()
                    except:
                        content = review.text.strip()

                # ì¤‘ë³µ ì²´í¬
                unique_id = (reviewer_name_text, review_date_text, content[:50])

                if unique_id in processed_review_identifiers:
                    continue

                processed_review_identifiers.add(unique_id)

                if content:
                    reviews_batch.append({
                        'product_name': product_name,
                        'review_content': content,
                        'review_date': review_date_text,
                        'reviewer_name': reviewer_name_text,
                    })

                    if idx % 20 == 0:
                        safe_print(f"      ... {product_name}: {len(reviews_batch)}ê°œ ì²˜ë¦¬ ì¤‘...")

            except Exception as e:
                continue

        safe_print(f"      âœ… {product_name}: ì´ {len(reviews_batch)}ê°œ ë¦¬ë·° ìˆ˜ì§‘ ì™„ë£Œ")
        return reviews_batch

    except Exception as e:
        safe_print(f"      âŒ {product_name}: ë¦¬ë·° ìˆ˜ì§‘ ì—ëŸ¬: {repr(e)}")

        try:
            current_url = driver.current_url
            safe_print(f"      ... í˜„ì¬ URL: {current_url}")
        except:
            pass

        return []


# -----------------------
# 6. ì›Œì»¤ í•¨ìˆ˜
# -----------------------

def process_single_product_reviews_only(args, driver_pool):
    """
    ë¦¬ë·°ë§Œ ìˆ˜ì§‘í•˜ëŠ” ì›Œì»¤ í•¨ìˆ˜
    """
    url, product_name, index, total = args
    driver = None

    try:
        driver = driver_pool.get()

        safe_print(f"      ... {product_name}: ë¦¬ë·° ìˆ˜ì§‘ ì‹œì‘")

        # ë¦¬ë·° ìˆ˜ì§‘
        reviews_batch = scrape_reviews(driver, product_name, url)

        # CSV ì €ì¥
        if reviews_batch:
            write_batch_to_csv(REVIEW_CSV_FILE, REVIEW_FIELDNAMES, reviews_batch)

        # ë”œë ˆì´
        delay = random.uniform(*RATE_LIMIT_DELAY_RANGE)
        safe_print(f"      ... ë‹¤ìŒ ì‘ì—…ê¹Œì§€ {delay:.1f}ì´ˆ ëŒ€ê¸° ...")
        time.sleep(delay)

        # ë“œë¼ì´ë²„ ë°˜í™˜
        driver_pool.put(driver)

        return {
            'status': 'success',
            'product_name': product_name,
            'review_count': len(reviews_batch),
            'index': index,
            'total': total
        }

    except Exception as e:
        if driver:
            safe_print(f"  (i) {product_name} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ. ë“œë¼ì´ë²„ ì¬ì‹œì‘...")
            try:
                driver.quit()
            except:
                pass

            try:
                new_user_agent = random.choice(USER_AGENT_LIST)
                new_driver = driver_pool._create_driver(user_agent=new_user_agent)
                driver_pool.put(new_driver)
                safe_print(f"  (i) ìƒˆ ë“œë¼ì´ë²„ ìƒì„± í›„ í’€ì— ë°˜í™˜ ì™„ë£Œ.")
            except Exception as e_create:
                safe_print(f"  (E) ìƒˆ ë“œë¼ì´ë²„ ìƒì„± ì‹¤íŒ¨: {e_create}.")
                pass

        return {
            'status': 'failed',
            'error': repr(e)[:120],
            'product_name': product_name,
            'index': index,
            'total': total
        }


# -----------------------
# 7. ë©”ì¸ í•¨ìˆ˜
# -----------------------

def main_review_only():
    """
    ê¸°ì¡´ í–¥ìˆ˜ ëª©ë¡ CSVì—ì„œ URLì„ ì½ì–´ì™€ì„œ ë¦¬ë·°ë§Œ ìˆ˜ì§‘
    """
    start_time = time.time()

    print("=" * 60)
    print(f"ğŸš€ Fragrantica ë¦¬ë·° ì „ìš© í¬ë¡¤ëŸ¬ ì‹œì‘")
    print(f"   (í‚¤ì›Œë“œ: {SEARCH_KEYWORD})")
    print(f"   (ë“œë¼ì´ë²„ í’€: {MAX_WORKERS}ê°œ)")
    print("=" * 60)

    # 1ï¸âƒ£ ê¸°ì¡´ í–¥ìˆ˜ CSV íŒŒì¼ í™•ì¸
    if not os.path.exists(PERFUME_CSV_FILE):
        print(f"\nâŒ ì˜¤ë¥˜: '{PERFUME_CSV_FILE}' íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!")
        print(f"   ë¨¼ì € í–¥ìˆ˜ ëª©ë¡ì„ ìˆ˜ì§‘í•˜ê±°ë‚˜, íŒŒì¼ëª…ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return

    # 2ï¸âƒ£ ë¦¬ë·° CSV íŒŒì¼ ì´ˆê¸°í™”
    try:
        if not os.path.exists(REVIEW_CSV_FILE):
            with open(REVIEW_CSV_FILE, 'w', newline='', encoding='utf-8-sig') as f:
                writer = csv.DictWriter(f, fieldnames=REVIEW_FIELDNAMES)
                writer.writeheader()
            print(f"âœ… ë¦¬ë·° CSV íŒŒì¼ ìƒì„±: {REVIEW_CSV_FILE}")
    except PermissionError as e:
        print("\n" + "!" * 60)
        print(f"âŒ [ì¹˜ëª…ì  ì˜¤ë¥˜] íŒŒì¼ ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤: {e}")
        print(f"   '{REVIEW_CSV_FILE}' íŒŒì¼ì´ Excel ë“±ì—ì„œ ì—´ë ¤ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        print("!" * 60 + "\n")
        sys.exit(1)

    # 3ï¸âƒ£ í–¥ìˆ˜ ëª©ë¡ CSVì—ì„œ URL ì½ê¸°
    print(f"\nğŸ“‚ '{PERFUME_CSV_FILE}'ì—ì„œ URL ë¡œë”© ì¤‘...")
    product_data_list = []

    try:
        with open(PERFUME_CSV_FILE, 'r', encoding='utf-8-sig') as f:
            reader = csv.DictReader(f)
            for row in reader:
                if row.get('url') and row.get('product_name'):
                    product_data_list.append({
                        'url': row['url'],
                        'product_name': row['product_name']
                    })
    except Exception as e:
        print(f"âŒ CSV íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        return

    if not product_data_list:
        print(f"âŒ '{PERFUME_CSV_FILE}'ì—ì„œ ìœ íš¨í•œ URLì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return

    print(f"âœ… ì´ {len(product_data_list)}ê°œ ì œí’ˆ ë°œê²¬")

    # 4ï¸âƒ£ ì˜ˆìƒ ì‹œê°„ ê³„ì‚°
    avg_delay = sum(RATE_LIMIT_DELAY_RANGE) / 2
    avg_time_per_product = 12 + avg_delay
    estimated_time_parallel = (len(product_data_list) * avg_time_per_product) / MAX_WORKERS
    print(f"\nğŸ“Š ì˜ˆìƒ ì†Œìš” ì‹œê°„ ({MAX_WORKERS}ê°œ ë³‘ë ¬): ì•½ {estimated_time_parallel / 60:.1f}ë¶„")

    # 5ï¸âƒ£ ë“œë¼ì´ë²„ í’€ ì´ˆê¸°í™”
    driver_pool = DriverPool(size=MAX_WORKERS)

    print("\n[ë¦¬ë·° ìˆ˜ì§‘ ì‹œì‘]")
    print("-" * 60)

    scraping_start = time.time()
    total = len(product_data_list)

    # 6ï¸âƒ£ ì‘ì—… ì¤€ë¹„
    tasks = [
        (item['url'], item['product_name'], i + 1, total)
        for i, item in enumerate(product_data_list)
    ]

    success_count = 0
    failed_count = 0
    total_reviews = 0

    # 7ï¸âƒ£ ë³‘ë ¬ ì²˜ë¦¬
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {
            executor.submit(process_single_product_reviews_only, task, driver_pool): task
            for task in tasks
        }

        for future in as_completed(futures):
            result = future.result()
            percentage = (result['index'] / result['total']) * 100

            if result['status'] == 'success':
                success_count += 1
                total_reviews += result['review_count']

                if result['review_count'] > 0:
                    safe_print(
                        f"[{result['index']}/{result['total']} ({percentage:.1f}%)] "
                        f"âœ… {result['product_name']} - ë¦¬ë·° {result['review_count']}ê°œ"
                    )
                else:
                    safe_print(
                        f"[{result['index']}/{result['total']} ({percentage:.1f}%)] "
                        f"â„¹ï¸  {result['product_name']} - ë¦¬ë·° ì—†ìŒ"
                    )
            else:
                failed_count += 1
                safe_print(
                    f"[{result['index']}/{result['total']} ({percentage:.1f}%)] "
                    f"âŒ {result['product_name']} - ì²˜ë¦¬ ì‹¤íŒ¨: {result['error']}"
                )

    # 8ï¸âƒ£ ë“œë¼ì´ë²„ í’€ ì¢…ë£Œ
    print("\nğŸ”§ ë“œë¼ì´ë²„ í’€ ì¢…ë£Œ ì¤‘...")
    driver_pool.close_all()

    scraping_time = time.time() - scraping_start
    total_time = time.time() - start_time

    # 9ï¸âƒ£ ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print("-" * 60)
    print("\n" + "=" * 60)
    print("âœ… ë¦¬ë·° ìˆ˜ì§‘ ì™„ë£Œ!")
    print("=" * 60)
    print(f"\nğŸ“Š í†µê³„:")
    print(f"   - ì„±ê³µ: {success_count}ê°œ")
    print(f"   - ì‹¤íŒ¨: {failed_count}ê°œ")
    print(f"   - ì´ ë¦¬ë·° ìˆ˜: {total_reviews}ê°œ")
    print(f"\nâ±ï¸  ì†Œìš” ì‹œê°„:")
    print(f"   - ë¦¬ë·° ìˆ˜ì§‘: {scraping_time / 60:.1f}ë¶„")
    print(f"   - ì „ì²´: {total_time / 60:.1f}ë¶„")
    print(f"\nğŸ“ ì €ì¥ëœ íŒŒì¼:")
    print(f"   - {REVIEW_CSV_FILE}")
    print("=" * 60)


# -----------------------
# 8. ì‹¤í–‰
# -----------------------

if __name__ == "__main__":
    main_review_only()